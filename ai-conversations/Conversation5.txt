AI- Conversations
------------------

Tool :- ChatGPT
Date :- 18-10-2025




Me :
-----

modify the code such that i need an option to select the visualisation of weather forecast(temperature, precipitation) 
by the user along with the response given by llama

AI Response:
-------------

Excellent ‚Äî we can upgrade your existing Ollama-powered weather assistant into a more interactive command-line dashboard that:

‚úÖ Generates natural human-like responses using llama3
‚úÖ Fetches live weather data from wttr.in
‚úÖ Gives the user an option to see weather visualizations for:

Temperature forecast (for next 3 days)

Precipitation forecast (for next 3 days)

Here‚Äôs your modified, complete code üëá

import requests
import json
import ollama
import re
import matplotlib.pyplot as plt

# ---------------- WEATHER DATA FETCH ---------------- #

def get_weather_data(location):
    """Fetch weather data for a given location using wttr.in API."""
    try:
        url = f"https://wttr.in/{location}?format=j1"
        response = requests.get(url)
        response.raise_for_status()
        return response.json()
    except Exception as e:
        return {"error": f"Failed to fetch weather data: {e}"}

# ---------------- PARSE QUESTION WITH OLLAMA3 ---------------- #

def parse_question_with_ai(question):
    """Use Ollama3 to extract structured info from user query."""
    prompt = (
        "Extract weather details from the question below. "
        "Return ONLY a JSON object with keys: location, time_period, and attribute. "
        "If not mentioned, set time_period='today' and attribute='weather'.\n\n"
        f"Question: {question}\nJSON:"
    )

    try:
        response = ollama.chat(model="llama3", messages=[{"role": "user", "content": prompt}])
        return response["message"]["content"]
    except Exception as e:
        print(f"‚ö†Ô∏è Error calling Ollama: {e}")
        return None

def extract_json(text):
    """Extract JSON object safely from AI output."""
    match = re.search(r"\{.*\}", text, re.DOTALL)
    if match:
        try:
            return json.loads(match.group())
        except json.JSONDecodeError:
            pass
    return None

# ---------------- GENERATE HUMANIZED RESPONSE ---------------- #

def generate_human_response(weather_data, question, location):
    """Use Ollama3 to generate a human-like weather reply."""
    if "error" in weather_data:
        return weather_data["error"]

    current = weather_data["current_condition"][0]
    desc = current["weatherDesc"][0]["value"]
    temp = current["temp_C"]
    precip = current["precipMM"]
    humidity = current["humidity"]

    weather_summary = (
        f"In {location.title()}, it's currently {desc.lower()} with {temp}¬∞C temperature, "
        f"humidity {humidity}%, and {precip} mm precipitation."
    )

    prompt = (
        "You are a helpful and friendly weather assistant. "
        "Using the given weather data and the user's question, respond in a short, natural human tone. "
        "If the question is about umbrella or raincoat, decide based on rain/precipitation data. "
        "Be concise and conversational.\n\n"
        f"Weather data: {weather_summary}\n"
        f"User question: {question}\n\n"
        "Example responses:\n"
        "- 'Yes, please take an umbrella ‚Äî it‚Äôs likely to rain today.'\n"
        "- 'No, it‚Äôs clear and sunny ‚Äî no umbrella needed.'\n"
        "- 'It‚Äôs cloudy but not rainy ‚Äî maybe keep a raincoat handy just in case.'\n\n"
        "Now respond naturally:"
    )

    try:
        response = ollama.chat(model="llama3", messages=[{"role": "user", "content": prompt}])
        return response["message"]["content"].strip()
    except Exception as e:
        return f"‚ö†Ô∏è Ollama error: {e}"

# ---------------- VISUALIZATION FUNCTIONS ---------------- #

def visualize_temperature_forecast(weather_data, location):
    """Plot temperature forecast for next 3 days."""
    days = weather_data["weather"][:3]
    dates = [d["date"] for d in days]
    avg_temps = [int(d["avgtempC"]) for d in days]

    plt.figure(figsize=(6, 4))
    plt.plot(dates, avg_temps, marker='o', color='orange', label='Avg Temperature (¬∞C)')
    plt.title(f"Temperature Forecast - {location.title()}")
    plt.xlabel("Date")
    plt.ylabel("Temperature (¬∞C)")
    plt.grid(True)
    plt.legend()
    plt.tight_layout()
    plt.show()

def visualize_precipitation_forecast(weather_data, location):
    """Plot precipitation forecast for next 3 days."""
    days = weather_data["weather"][:3]
    dates = [d["date"] for d in days]
    avg_precip = []

    for day in days:
        hourly = day["hourly"]
        total_precip = sum(float(h["precipMM"]) for h in hourly)
        avg_precip.append(round(total_precip / len(hourly), 2))

    plt.figure(figsize=(6, 4))
    plt.bar(dates, avg_precip, color='skyblue', edgecolor='black')
    plt.title(f"Precipitation Forecast - {location.title()}")
    plt.xlabel("Date")
    plt.ylabel("Avg Precipitation (mm)")
    plt.tight_layout()
    plt.show()

# ---------------- MAIN FUNCTION ---------------- #

def get_weather_response(question):
    """Main function to handle user question and return AI-generated answer."""
    parsed = parse_question_with_ai(question)
    if not parsed:
        return None, "Sorry, I couldn‚Äôt understand your question."

    info = extract_json(parsed)
    if not info:
        return None, "Sorry, I couldn‚Äôt extract valid details."

    location = info.get("location", "Perth").strip() or "Perth"
    weather_data = get_weather_data(location)
    ai_response = generate_human_response(weather_data, question, location)

    return weather_data, ai_response

# ---------------- RUN THE ASSISTANT ---------------- #

if __name__ == "__main__":
    print("üå¶Ô∏è Weather Assistant ‚Äî powered by Ollama 3")
    print("Type your question (e.g., 'Do I need a raincoat today in Hyderabad?')\n")

    while True:
        question = input("You: ")
        if question.lower() in ["exit", "quit"]:
            print("üëã Goodbye! Stay safe!")
            break

        weather_data, answer = get_weather_response(question)
        print(f"\nü§ñ Assistant: {answer}\n")

        if weather_data:
            print("Would you like to see a visualization?")
            print("1Ô∏è‚É£ Temperature Forecast\n2Ô∏è‚É£ Precipitation Forecast\n3Ô∏è‚É£ Skip")
            choice = input("Enter choice (1/2/3): ").strip()

            if choice == "1":
                visualize_temperature_forecast(weather_data, weather_data["nearest_area"][0]["areaName"][0]["value"])
            elif choice == "2":
                visualize_precipitation_forecast(weather_data, weather_data["nearest_area"][0]["areaName"][0]["value"])
            else:
                print("‚úÖ Skipping visualization.\n")


üß† What‚Äôs New:

‚úÖ Keeps your original AI flow (Ollama ‚Üí JSON extraction ‚Üí weather summary ‚Üí humanized response)
‚úÖ Adds an optional visualization menu after the response
‚úÖ Plots two weather graphs:

Temperature forecast (3 days)

Precipitation forecast (3 days)


üí¨ Example Interaction:
You: Do I need an umbrella today in Sydney?

ü§ñ Assistant: Yes, please take an umbrella ‚Äî light rain is expected today.

Would you like to see a visualization?
1Ô∏è‚É£ Temperature Forecast
2Ô∏è‚É£ Precipitation Forecast
3Ô∏è‚É£ Skip
Enter choice (1/2/3): 2
üìä (Shows rainfall chart)



-----------------------------------------------------------------------------------------------------


Me : 
-----

Modify the app.py and index.html code such that I need the UI like a conversation between the AI and the user and the past conversations should be saved


AI Response:
-------------

Perfect üëç I can help you make your chatbot behave like a real chat conversation ‚Äî showing both user and AI messages one below another, and saving past messages (persistent within the current session).

We'll modify both app.py and index.html accordingly.

‚úÖ Updated app.py

This version keeps a chat history and returns the entire conversation each time.

from flask import Flask, render_template, request, jsonify
import requests, json, ollama, re

app = Flask(__name__)
chat_history = []  # Stores conversation during the session


# ---------------- WEATHER DATA FETCH ---------------- #

def get_weather_data(location):
    """Fetch weather data for a given location using wttr.in API."""
    url = f"https://wttr.in/{location}?format=j1"
    response = requests.get(url)
    response.raise_for_status()
    return response.json()


# ---------------- PARSE QUESTION WITH OLLAMA3 ---------------- #

def parse_question_with_ai(question):
    """Use Ollama3 to extract structured info from user query."""
    prompt = (
        "Extract the location, time period, and weather attribute from the following weather question. "
        "Return ONLY a JSON object with keys: location, time_period, and attribute. "
        "If not mentioned, assume time_period='today' and attribute='weather'.\n\n"
        f"Question: {question}\nJSON:"
    )
    try:
        response = ollama.chat(model="llama3", messages=[{"role": "user", "content": prompt}])
        return response["message"]["content"]
    except Exception as e:
        print(f"‚ö†Ô∏è Ollama parse error: {e}")
        return None


def extract_json(text):
    """Extract JSON object safely from AI output."""
    match = re.search(r"\{.*\}", text, re.DOTALL)
    if match:
        try:
            return json.loads(match.group())
        except json.JSONDecodeError:
            return None
    return None


# ---------------- GENERATE HUMANIZED RESPONSE ---------------- #

def generate_human_response(weather_data, question, location):
    """Use Ollama3 to generate a human-like, short weather response."""
    current = weather_data["current_condition"][0]
    desc = current["weatherDesc"][0]["value"]
    temp = current["temp_C"]
    feels_like = current["FeelsLikeC"]
    precip = current["precipMM"]
    humidity = current["humidity"]
    wind = current["windspeedKmph"]

    today_summary = (
        f"The current weather in {location.title()} is {desc.lower()} with a temperature of {temp}¬∞C "
        f"(feels like {feels_like}¬∞C), humidity {humidity}%, and precipitation of {precip} mm. "
        f"Wind speed is around {wind} km/h."
    )

    prompt = (
        "You are a friendly weather assistant. "
        "Using the given current weather data and the user's question, respond in a short, natural human tone. "
        "Do NOT show numerical values or forecasts. Be conversational and direct.\n\n"
        f"Weather data: {today_summary}\n"
        f"User question: {question}\n\n"
        "Example responses:\n"
        "- 'Yes, you‚Äôll probably need an umbrella ‚Äî it looks rainy today.'\n"
        "- 'No, it‚Äôs sunny and clear ‚Äî no umbrella needed.'\n"
        "- 'It‚Äôs warm and pleasant outside ‚Äî perfect weather!'\n"
        "- 'Looks cloudy but dry ‚Äî you should be fine without a raincoat.'\n\n"
        "Now reply naturally:"
    )

    try:
        response = ollama.chat(model="llama3", messages=[{"role": "user", "content": prompt}])
        return response["message"]["content"].strip()
    except Exception as e:
        return f"‚ö†Ô∏è Ollama error: {e}"


# ---------------- ROUTES ---------------- #

@app.route("/")
def index():
    return render_template("index.html")


@app.route("/ask", methods=["POST"])
def ask():
    """Handle chatbot queries and maintain conversation history."""
    global chat_history
    data = request.get_json()
    question = data.get("question", "").strip()
    if not question:
        return jsonify({"error": "Please enter a question."}), 400

    # Add user message
    chat_history.append({"sender": "user", "text": question})

    parsed = parse_question_with_ai(question)
    info = extract_json(parsed) if parsed else None
    location = info.get("location", "Perth") if info else "Perth"

    try:
        weather_data = get_weather_data(location)
        ai_response = generate_human_response(weather_data, question, location)
        chat_history.append({"sender": "ai", "text": ai_response})
        return jsonify({"chat": chat_history})
    except Exception as e:
        error_msg = f"‚ö†Ô∏è Error: {e}"
        chat_history.append({"sender": "ai", "text": error_msg})
        return jsonify({"chat": chat_history})


@app.route("/reset", methods=["POST"])
def reset_chat():
    """Clear chat history."""
    global chat_history
    chat_history = []
    return jsonify({"message": "Chat history cleared"})


@app.route("/dashboard", methods=["POST"])
def dashboard():
    """Dashboard for weather data visualisation."""
    data = request.get_json()
    location = data.get("location", "Perth")
    info_type = data.get("infoType", "both")
    time_period = data.get("timePeriod", "today")

    weather_data = get_weather_data(location)

    if time_period == "today":
        dates = ["Today"]
        temps = [int(weather_data["current_condition"][0]["temp_C"])]
        precips = [float(weather_data["current_condition"][0]["precipMM"])]
    else:
        dates = [d["date"] for d in weather_data["weather"][:3]]
        temps = [int(d["avgtempC"]) for d in weather_data["weather"][:3]]
        precips = [
            sum(float(h["precipMM"]) for h in d["hourly"]) / len(d["hourly"])
            for d in weather_data["weather"][:3]
        ]

    return jsonify({
        "dates": dates,
        "temps": temps,
        "precips": precips,
        "infoType": info_type
    })


if __name__ == "__main__":
    app.run(debug=True)




‚úÖ Updated index.html

Below is your full front-end file with:

Chat bubble layout üí¨

Persistent chat history

Reset chat button


<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>AI Weather Assistant</title>
<style>
body {
  font-family: Arial, sans-serif;
  background: #f5f7fa;
  margin: 0;
  padding: 0;
}
header {
  background: #0078d7;
  color: white;
  padding: 15px;
  text-align: center;
  font-size: 24px;
}
.container {
  width: 90%;
  max-width: 900px;
  margin: 20px auto;
  background: white;
  padding: 20px;
  border-radius: 10px;
  box-shadow: 0 0 10px rgba(0,0,0,0.1);
}
.tabs {
  display: flex;
  justify-content: space-around;
  margin-bottom: 20px;
}
.tab {
  flex: 1;
  text-align: center;
  padding: 10px;
  cursor: pointer;
  background: #e9e9e9;
  border-radius: 8px;
  transition: 0.3s;
}
.tab.active {
  background: #0078d7;
  color: white;
  font-weight: bold;
}
.chat-box {
  height: 400px;
  overflow-y: auto;
  background: #f0f0f0;
  padding: 15px;
  border-radius: 10px;
}
.message {
  margin: 10px 0;
  padding: 10px 15px;
  border-radius: 15px;
  max-width: 70%;
}
.user {
  background: #0078d7;
  color: white;
  align-self: flex-end;
  margin-left: auto;
}
.ai {
  background: #e0e0e0;
  color: black;
  align-self: flex-start;
  margin-right: auto;
}
.chat-input {
  display: flex;
  gap: 10px;
  margin-top: 10px;
}
input[type="text"] {
  flex: 1;
  padding: 10px;
  border-radius: 5px;
  border: 1px solid #ccc;
}
button {
  background: #0078d7;
  color: white;
  border: none;
  padding: 10px 15px;
  border-radius: 5px;
  cursor: pointer;
}
button:hover { background: #005fa3; }
.dashboard-area { display: none; }
canvas {
  margin-top: 25px;
  max-width: 100%;
  display: none;
}
</style>
</head>
<body>

<header>üå§Ô∏è AI Weather Assistant</header>
<div class="container">
  <div class="tabs">
    <div class="tab active" id="chatTab">Chatbot</div>
    <div class="tab" id="dashTab">Weather Dashboard</div>
  </div>

  <!-- Chatbot Section -->
  <div id="chatArea">
    <h2>Ask the AI Assistant</h2>
    <div class="chat-box" id="chatBox"></div>
    <div class="chat-input">
      <input type="text" id="chatInput" placeholder="Type your question...">
      <button id="askBtn">Ask</button>
      <button id="resetBtn" style="background:#d9534f;">Reset</button>
    </div>
  </div>

  <!-- Weather Dashboard Section -->
  <div class="dashboard-area" id="dashArea">
    <h2>Weather Dashboard</h2>
    <label>Enter Location:</label>
    <input type="text" id="location" placeholder="Enter city name">
    <br><br>
    <label>Choose Info Type:</label>
    <select id="infoType">
      <option value="temperature">Temperature</option>
      <option value="precipitation">Precipitation</option>
      <option value="both" selected>Both</option>
    </select>
    <br><br>
    <label>Time Period:</label>
    <select id="timePeriod">
      <option value="today">Today</option>
      <option value="next3days">Next 3 Days</option>
    </select>
    <br><br>
    <button id="fetchBtn">Get Weather Data</button>
    <canvas id="tempChart"></canvas>
    <canvas id="precipChart"></canvas>
  </div>
</div>

<script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
<script>
const chatBox = document.getElementById('chatBox');
const chatInput = document.getElementById('chatInput');
const chatTab = document.getElementById('chatTab');
const dashTab = document.getElementById('dashTab');
const dashArea = document.getElementById('dashArea');
const chatArea = document.getElementById('chatArea');

chatTab.onclick = () => {
  chatTab.classList.add('active');
  dashTab.classList.remove('active');
  chatArea.style.display = 'block';
  dashArea.style.display = 'none';
};
dashTab.onclick = () => {
  dashTab.classList.add('active');
  chatTab.classList.remove('active');
  chatArea.style.display = 'none';
  dashArea.style.display = 'block';
};

function addMessage(sender, text) {
  const msg = document.createElement('div');
  msg.classList.add('message', sender);
  msg.innerText = (sender === 'user' ? 'üßë ' : 'ü§ñ ') + text;
  chatBox.appendChild(msg);
  chatBox.scrollTop = chatBox.scrollHeight;
}

document.getElementById('askBtn').onclick = async () => {
  const question = chatInput.value.trim();
  if (!question) return alert("Please enter a question!");
  addMessage('user', question);
  chatInput.value = "";

  const res = await fetch("/ask", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ question })
  });
  const data = await res.json();

  chatBox.innerHTML = "";
  data.chat.forEach(msg => addMessage(msg.sender, msg.text));
};

document.getElementById('resetBtn').onclick = async () => {
  await fetch("/reset", { method: "POST" });
  chatBox.innerHTML = "";
  addMessage('ai', "Chat cleared. How can I assist you with the weather?");
};

// DASHBOARD CHART
let tempChart = null;
let precipChart = null;
document.getElementById('fetchBtn').onclick = async () => {
  const location = document.getElementById('location').value.trim() || "Perth";
  const infoType = document.getElementById('infoType').value;
  const timePeriod = document.getElementById('timePeriod').value;

  const res = await fetch("/dashboard", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ location, infoType, timePeriod })
  });
  const data = await res.json();

  const tempCanvas = document.getElementById('tempChart');
  const precipCanvas = document.getElementById('precipChart');

  if (tempChart && tempChart.destroy) tempChart.destroy();
  if (precipChart && precipChart.destroy) precipChart.destroy();

  tempCanvas.style.display = "none";
  precipCanvas.style.display = "none";

  if (infoType === "temperature" || infoType === "both") {
    tempCanvas.style.display = "block";
    tempChart = new Chart(tempCanvas.getContext('2d'), {
      type: 'line',
      data: {
        labels: data.dates,
        datasets: [{
          label: "Temperature (¬∞C)",
          data: data.temps,
          borderColor: 'red',
          backgroundColor: 'rgba(255,99,132,0.2)',
          fill: true
        }]
      },
      options: { responsive: true }
    });
  }

  if (infoType === "precipitation" || infoType === "both") {
    precipCanvas.style.display = "block";
    precipChart = new Chart(precipCanvas.getContext('2d'), {
      type: 'bar',
      data: {
        labels: data.dates,
        datasets: [{
          label: "Precipitation (mm)",
          data: data.precips,
          backgroundColor: 'skyblue',
          borderColor: 'blue'
        }]
      },
      options: { responsive: true }
    });
  }
};
</script>
</body>
</html>



üí° Result

Chat looks like this:

üßë You: Do I need an umbrella tomorrow in Sydney?
ü§ñ AI: Yes, you‚Äôll probably need an umbrella ‚Äî it looks rainy tomorrow.
üßë You: How‚Äôs the temperature?
ü§ñ AI: It‚Äôs warm and pleasant outside ‚Äî perfect weather!


Past chat is maintained

‚ÄúReset‚Äù clears conversation

Dashboard still works perfectly
